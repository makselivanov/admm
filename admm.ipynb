{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff33aa34-9a5f-40b1-897c-a9fdbbc7d986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dwave.samplers import SimulatedAnnealingSampler\n",
    "import clarabel\n",
    "clarabel_settings = clarabel.DefaultSettings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14706cb-4d38-4f64-8b93-7da57ff512a1",
   "metadata": {},
   "source": [
    "### Рюкзак\n",
    "А именно *Multidimensional Multiple-Choice Quadratic Knapsack Problem* (MdMCQKP)\n",
    "\n",
    "Пусть:\n",
    "- N: количество предметов, которые можно положить в рюкзак\n",
    "- M: размерность рюкзака, то есть количество различных ограничений в виде неравенств\n",
    "- K: количество различных классов, на которые разбиваются предметы\n",
    "- $x$: Бинарный вектор размера $N$\n",
    "\n",
    "Тогда:\n",
    "- profits (P): симметричная двухмерная матрица $N\\times N$, где $P_{ij}$ это профит, если выбраны предметы $i$ и $j$ (для $i \\not = j$: $P_{i, j}$ равен половине профита). Тогда $x^TPx$ это суммарный профит.\n",
    "- groups (G): бинарная матрица размера $K \\times N$, которая задает классы, для строчки $i$ будет выбран  один и только один предмет, среди которых в в соотвествующем столбце будет стоять $1$. То есть ограничение будет $\\forall i \\in \\{1, \\ldots K\\}: \\sum\\limits_{j=1}^{N}G_{ij}x_j = 1$.\n",
    "    Также можно записать как $Gx = \\mathbb{1}_K$, где $\\mathbb{1}_K$ - вектор из 1 размера K.\n",
    "- capacity (c): вектор размера $M$, где $c_i$ равен вместимости рюкзака по измерению $i$.\n",
    "- weights (W): матрица размера $M \\times N$, где $W_{ij}$ равна весу(размеру) предмета $j$ для измерения рюкзака $i$.\n",
    "То есть ограничение будет $\\forall i \\in \\{1, \\ldots M\\}: \\sum\\limits_{j=1}^{N}W_{ij}x_j \\le c_i$. Также можно записать это как $Wx \\le c$, где неравенство имеется в виду по поокординатное.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42d99142-6d4e-48fd-bb51-e079cbec17f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Валидирует переданные данные, возвращает (N, M, K) из описания сверху\n",
    "def validatorMdMCQ(profits: np.ndarray, \n",
    "                   groups: np.ndarray, \n",
    "                   weights: np.ndarray, \n",
    "                   capacity: np.ndarray, \n",
    "                   rtol=1e-05, atol=1e-08):\n",
    "    N = profits.shape[0]\n",
    "    M = capacity.shape[0]\n",
    "    K = groups.shape[0]\n",
    "    \n",
    "    if len(profits.shape) != 2:\n",
    "        raise ValueError(\"profits is not matrix (not 2d array)\")\n",
    "    if len(groups.shape) != 2:\n",
    "        raise ValueError(\"groups is not matrix (not 2d array)\")\n",
    "    if len(weights.shape) != 2:\n",
    "        raise ValueError(\"weights is not matrix (not 2d array)\")\n",
    "    if len(capacity.shape) != 1:\n",
    "        raise ValueError(\"capacity is not vector (not 1d array)\")\n",
    "\n",
    "    if profits.shape != (N, N):\n",
    "        raise ValueError(\"profits is not square matrix (not (N, N) matrix)\")\n",
    "    if groups.shape != (K, N):\n",
    "        raise ValueError(\"groups is not (K, N) matrix\")\n",
    "    if weights.shape != (M, N):\n",
    "        raise ValueError(\"weights is not (M, N) matrix\")\n",
    "    \n",
    "    isSymMatrix = lambda matrix: np.allclose(matrix, matrix.T, rtol=rtol, atol=atol) \n",
    "    if not isSymMatrix(profits):\n",
    "        raise ValueError(\"profits is not symmetric matrix\")\n",
    "    isBinaryMatrix = lambda matrix: np.array_equal(matrix, matrix.astype(bool))\n",
    "    if not isBinaryMatrix(groups):\n",
    "        raise ValueError(\"groups is not binary matrix\")\n",
    "    return N, M, K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0766df41-a856-4910-bbc1-1cf19fb4fd55",
   "metadata": {},
   "source": [
    "### Переводим в ADMM задачу\n",
    "\n",
    "Сначала введем еще одно обозначение.\n",
    "Пусть новая переменная $u \\in \\mathbb{R}_{\\ge 0}^M$ и мы заменим $Wx < c$ на равенство $Wx + u = c$. Но это тоже самое, что $Wx + u - c = 0$, а это эквивалентно $\\|Wx + u - c\\|_2^2 \\le 0$\n",
    "\n",
    "В IV секции в статье про ADMM у нас получились обозначения:\n",
    "- $q(x) = -x^TPx$ - является квадратичным\n",
    "- $\\mathcal{X}$ - это множество из всех бинарных векторов размерности N\n",
    "- $\\mathcal{U} = \\mathbb{R}_{\\ge 0}^M, u = u$ - множество будет выпуклым\n",
    "- $\\varphi(u) = 0$, оно у нас не используется\n",
    "- $G = G$, $b = \\mathbb{1}_K$ тут у нас обозначения совпали\n",
    "- $g(x) = 0$, оно у нас не используется\n",
    "- $\\ell(x, u)$ заменится на $\\|Wx + u - c\\|_2^2$ (x и u в качестве себя) - это функция должна быть совместно выпуклой, сейчас я это не буду доказывать\n",
    "\n",
    "Наша текущая задача \n",
    "\n",
    "\\begin{equation}\n",
    "\\min_{x\\in\\mathcal{X}, u \\in \\mathbb{R}_{\\ge 0}^M \\subset \\mathbb{R}^M} -x^TPx\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\text{subject to: }Gx=\\mathbb{1}_K, \\| Wx + u - c \\|_2^2 \\le 0\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8507600e-1140-47a8-ba2c-e72a4de0ef3e",
   "metadata": {},
   "source": [
    "Сделаем следующий шаг согласно статье, когда мы вводим новую переменную $z$ и ослабляем равенство $Gx=\\mathbb{1}_K$. Пусть $\\alpha > 0$ - какое очень большое число\n",
    "\n",
    "\\begin{equation}\n",
    "\\min_{x\\in\\mathcal{X}, z \\in \\mathbb{R}^N, u \\in \\mathbb{R}_{\\ge 0}^M} -x^TPx + \\dfrac{\\alpha}{2}\\|Gx - \\mathbb{1}_K\\|_2^2\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\text{subject to: }\\| Wz + u - c \\|_2^2 \\le 0, x = z\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aa1236-8b16-4506-ab7a-1d4dd7f5c68b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Теперь мы назовем вектор $\\overline{x}$ размера $N + M$, где первые $N$ чисел образуют вектор $z$, а последние $M$ образуют вектор $u$, то есть мы вертикально их разместили, $z$ над $u$ \\n\n",
    "\n",
    "Тогда:\n",
    "- $f_0(x) := -x^TPx + \\dfrac{\\alpha}{2}\\|Gx - \\mathbb{1}_K\\|^2_2$\n",
    "- $\\overline{X} := \\left\\{(z\\in\\mathbb{R}^N, u\\in\\mathbb{R}_{\\ge0}^M)\\Big| \\|Wz + u - c\\|_2^2 \\le 0\\right\\}$\n",
    "- $\\iota_X(x) := 0$ если $x\\in X$, иначе равна $+\\infty$, это функция индикатор, которая снизу полунепрерывная\n",
    "- В приведенной статье $f_1(\\overline{x}) := \\iota_{\\overline{X}}(\\overline{x})$\n",
    "- **В данной статье** зададим функцию как $f_1(\\overline{x}) := \\dfrac{\\beta}{2}\\|Wz + u - c\\|_2^2$, где $z, u$ такие, что $\\overline{x} = [z^T; u^T]^T$\n",
    "\n",
    "Тогда задача станет (2-ADMM-H):\n",
    "\\begin{equation}\n",
    "\\min_{x\\in\\mathcal{X}, \\overline{x}\\in\\mathbb{R}^{N+M}} f_0(x) + f_1(\\overline{x})\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\text{subject to: }A_0x + A_1\\overline{x} = 0\n",
    "\\end{equation}\n",
    "\n",
    "где:\n",
    "- $A_0 = E_N$ - единичная матрица размера $N\\times N$\n",
    "- $A_1 = [-E_N; 0_{N\\times M}]$, получится матрица размера $N \\times (N + M)$\n",
    "\n",
    "Это мы свели задачу к 2-блочному ADMM задачу"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fff525c-30ad-4553-b256-eed6ea143356",
   "metadata": {},
   "source": [
    "Теоретически нам достаточно 2-блочного ADMM, так как у нас есть гладкость $f_1(\\overline{x})$, но мы можем свести к 3-блочному ADMM, потому что на практике он быстрее сходится.\n",
    "\n",
    "Тогда задача станет (3-ADMM-H):\n",
    "\n",
    "\\begin{equation}\n",
    "\\min_{x\\in\\mathcal{X}, \\overline{x}\\in\\mathbb{R}^{N+M}, y\\in\\mathbb{R}^{N}} f_0(x) + f_1(\\overline{x}) + \\dfrac{\\gamma}{2}\\|y\\|^2_2\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\text{subject to: }A_0x + A_1\\overline{x} = y\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7910b690-3f56-442f-a86e-ecda141f182c",
   "metadata": {},
   "source": [
    "#### Выпуклость $f_1$\n",
    "\n",
    "Перед тем, как начать расписывать подробно алгоритм, докажем, что $f_1$ является выпуклой функией от $\\overline{x}$. (Понятно, что умножение на константу не влияет на выпуклость). Пусть $\\overline{x} = [z^T; u^T]^T$\n",
    "\n",
    "$$f_1(\\overline{x}) = \\|Wz + u - c\\|_2^2$$\n",
    "\n",
    "Перепишем функцию по другому\n",
    "\n",
    "$$f_1(\\overline{x}) = \\|[W, E_M]\\overline{x} - c\\|_2^2$$\n",
    "\n",
    "Но заметим, что $[W, E_M]\\overline{x} - c$ является аффиной картой между $\\mathbb{R}^{N+M}$ и $\\mathbb{R}^{M}$. Также мы знаем $\\|\\cdot\\|_2^2$ является выпуклой функцией. Но тогда просто скажем, что свойство выпуклости сохраняется даже при аффинных карт. Вот и все доказательство"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b3d1f3-9bf3-481d-9418-896fa2c060bc",
   "metadata": {},
   "source": [
    "#### Алгоритм 3-ADMM-H\n",
    "\n",
    "Распишем подробей шаги для трехблочного алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a831c3d9-138d-472c-81be-af1acbcf44a2",
   "metadata": {},
   "source": [
    "Пусть мы как-то инициилизировали начальные переменные $x_0, \\overline{x}_0, \\lambda_0$, также зададим константы $epochs$, $\\varrho$, $\\alpha$, $\\beta$, $\\gamma$, $\\mu$, $\\varepsilon$\n",
    "\n",
    "Тогда мы $epochs$ раз будем повторять шаги, пусть переменная $t$ говорит номер эпохи начиная с $1$ (также же проверяется, что $\\|A_0x_t + A_1\\overline{x}_k - y_k\\|_2 < \\varepsilon$, иначе останавливаемся):\n",
    "\n",
    "1. **QUBO блок**\n",
    "   \n",
    "   В этом блоке будем обновлять $x_t$, решая QUBO задачу.\n",
    "   $$x_t = \\underset{x\\in\\{0,1\\}^N}{\\arg\\min} -x^TPx+\\dfrac{\\alpha}{2}\\|Gx - \\mathbb{1}_K\\|_2^2 + \\lambda_{t-1}^TA_0x + \\dfrac{\\varrho}{2}\\|A_0x + A_1\\overline{x}_{t-1} - y_{t-1}\\|^2_2$$\n",
    "\n",
    "   Подставим значия $A_0=E_N, A_1=[-E_N, 0_{N\\times M}]$, так же пусть $\\overline{x}_t = [z_t^T, u_t^T]^T$\n",
    "\n",
    "   $$x_t = \\underset{x\\in\\{0,1\\}^N}{\\arg\\min} -x^TPx+\\dfrac{\\alpha}{2}\\|Gx - \\mathbb{1}_K\\|_2^2 + \\lambda_{t-1}^Tx + \\dfrac{\\varrho}{2}\\|x - z_{t-1}-y_{t-1}\\|^2_2$$\n",
    "\n",
    "    Распишем $\\|Eq\\|_2^2$ как $Eq^TEq$ для векторов\n",
    "\n",
    "   $$x_t = \\underset{x\\in\\{0,1\\}^N}{\\arg\\min} -x^TPx+\\dfrac{\\alpha}{2}(Gx - \\mathbb{1}_K)^T(Gx - \\mathbb{1}_K) + \\lambda_{t-1}^Tx + \\dfrac{\\varrho}{2}(x - z_{t-1}-y_{t-1})^T(x - z_{t-1}-y_{t-1})$$\n",
    "\n",
    "    Раскроем скобки, уберем константы\n",
    "\n",
    "   $$x_t = \\underset{x\\in\\{0,1\\}^N}{\\arg\\min} -x^TPx+\\dfrac{\\alpha}{2}(x^TG^TGx - \\mathbb{1}_K^TGx - x^TG^T\\mathbb{1}_K) + \\lambda_{t-1}^Tx + \\dfrac{\\varrho}{2}(x^Tx - (z_{t-1}+y_{y_{t-1}})^Tx - x^T(z_{t-1}+y_{t-1}))$$\n",
    "\n",
    "    Приводим в красивый вид (замечу, что $b^Tx = x^Tb$ при условии, что $b$ - вектор, так как $b^Tx$ - скаляр)\n",
    "\n",
    "   $$x_t = \\underset{x\\in\\{0,1\\}^N}{\\arg\\min}\\ \n",
    "   x^T\\left(-P+\\frac{\\alpha}{2}G^TG+\\frac{\\varrho}{2}E_N\\right)x - \n",
    "   \\left(\\alpha G^T\\mathbb{1}_K + \\varrho (z_{t-1}+y_{t-1}) - \\lambda_{t-1}\\right)^Tx$$\n",
    "\n",
    "   Чтобы сделать задачу $x^TAx + b^Tx$ чисто $x^TQx$ при условии, что $x$ - бинарный вектор, то надо просто на главную диагональ $A$ добавить вектор $b$, так как $x_{[i]}^2 = x_{[i]}$, где $x_{[i]}$ - $i$-ая координата $x$\n",
    "3. **Convex block**\n",
    "\n",
    "   **Первый способ**\n",
    "\n",
    "   Что нам нужно\n",
    "\n",
    "   $$\\overline{x}_k = \\underset{z\\in\\mathbb{R}^{N},u\\in\\mathbb{R}_{\\ge0}^M, \\overline{x}=[z^T;u^T]^T}{\\arg\\min}\\ \\dfrac{\\beta}{2}\\|[Wz + u - c \\|_2^2 + \\lambda_{t-1}^Tz + \\dfrac{\\varrho}{2}\\|x_t+z-y_{t-1}\\|_2^2$$\n",
    "\n",
    "   Но на самом деле же нам надо сделать $Wz + u = c$ при $u \\in \\mathbb{R}^M$ и минимизировать остальную часть\n",
    "\n",
    "   $$\\overline{x}_k = \\underset{z\\in\\mathbb{R}^{N},\\overline{x}=[z^T;u^T]^T}{\\arg\\min}\\ \\dfrac{\\varrho}{2}z^Tz + \\lambda_{t-1}^Tz + \\varrho(x_t-y_{t-1})^Tz$$\n",
    "\n",
    "   $$\\text{subject to: } Wz + u = c,\\ u \\in \\mathbb{R}^M_{\\ge0}$$\n",
    "\n",
    "   Такое принимает решатель\n",
    "\n",
    "   **Второй способ(не доделан пока)**\n",
    "\n",
    "   **В данный момент тут проблема, мы не утверждаем, что u часть у $\\overline{x}$ положительна, может понадобиться слабое ограничение на это, что то типо квадрат минимальной координаты, которые меньше нуля?**\n",
    "\n",
    "   В этом блоке будем обновлять $\\overline{x}_t$, решая выпуклую задачу.\n",
    "\n",
    "    $$\\overline{x}_k = \\underset{\\overline{x}\\in\\mathbb{R}^{N+M}}{\\arg\\min}\\ \\dfrac{\\beta}{2}\\|[W; E_M]\\overline{x} - c \\|_2^2 + \\lambda_{t-1}^TA_1\\overline{x} + \\dfrac{\\varrho}{2}\\|x_t+A_1\\overline{x}-y_{t-1}\\|_2^2$$\n",
    "\n",
    "   Подставим $\\|\\cdot\\|^2_2$ как в прошлом блоке\n",
    "\n",
    "   $$\\overline{x}_k = \\underset{\\overline{x}\\in\\mathbb{R}^{N+M}}{\\arg\\min}\\ \\dfrac{\\beta}{2}([W; E_M]\\overline{x} - c)^T([W; E_M]\\overline{x} - c) + \\lambda_{t-1}^TA_1\\overline{x} + \\dfrac{\\varrho}{2}(x_t+A_1\\overline{x}-y_{t-1})^T(x_t+A_1\\overline{x}-y_{t-1})$$\n",
    "\n",
    "   Раскрываем скобки, убираем константы\n",
    "\n",
    "   $$\\overline{x}_k = \\underset{\\overline{x}\\in\\mathbb{R}^{N+M}}{\\arg\\min}\\ \\dfrac{\\beta}{2}(\\overline{x}^T[W; E_M]^T[W; E_M]\\overline{x} - c^T[W; E_M]\\overline{x} - \\overline{x}^T[W; E_M]^Tc) + \\lambda_{t-1}^TA_1\\overline{x} + \\dfrac{\\varrho}{2}(\\overline{x}^TA_1^T(x_t-y_{t-1}) + (x_t-y_{t-1})^TA_1\\overline{x}+\\overline{x}^TA_1^TA_1\\overline{x})$$\n",
    "\n",
    "   Приводим в красивый вид, подставим $A_1 = [-E_N; 0_{N\\times M}]$, также помним утверждение в прошлом блоке про $b^Tx = x^Tb$\n",
    "\n",
    "   $$\\overline{x}_k = \\underset{\\overline{x}\\in\\mathbb{R}^{N+M}}{\\arg\\min}\\ \\overline{x}^T\\left(\\frac{\\beta}{2}[W; E_M]^T[W; E_M] + \\frac{\\varrho}{2}[-E_N; 0_{N\\times M}]^T[-E_N; 0_{N\\times M}]\\right)\\overline{x} + \\left(-\\beta c^T[W;E_M] + \\lambda_{t-1}^T[-E_N; 0_{N\\times M}] + \\varrho (x_t-y_{t-1})^T[-E_N; 0_{N\\times M}]\\right)\\overline{x}$$\n",
    "\n",
    "   Это уже можно положить просто в решатель\n",
    "\n",
    "5. **Convex+quadratic block**\n",
    "\n",
    "   В этом блоке будем обновлять $y_k$\n",
    "\n",
    "    $$y_k = \\underset{y\\in\\mathbb{R}^N}{\\arg\\min}\\ \\dfrac{\\gamma}{2}\\|y\\|_2^2 - \\lambda_{t-1}^Ty+\\dfrac{\\varrho}{2}\\|x_t+A_1\\overline{x}_t-y\\|_2^2$$\n",
    "\n",
    "   Заменим $\\|\\cdot\\|_2^2$\n",
    "\n",
    "   $$y_k = \\underset{y\\in\\mathbb{R}^N}{\\arg\\min}\\ \\dfrac{\\gamma}{2}y^Ty - \\lambda_{t-1}^Ty+\\dfrac{\\varrho}{2}(x_t+A_1\\overline{x}_t-y)^T(x_t+A_1\\overline{x}_t-y)$$\n",
    "\n",
    "   Раскроем и сократим\n",
    "\n",
    "   $$y_k = \\underset{y\\in\\mathbb{R}^N}{\\arg\\min}\\ \\dfrac{\\gamma}{2}y^Ty - \\lambda_{t-1}^Ty+\\dfrac{\\varrho}{2}(-(x_t+A_1\\overline{x}_t)^Ty - y^T(x_t+A_1\\overline{x}_t) - y^Ty)$$\n",
    "\n",
    "   Приведем в красивый вид\n",
    "\n",
    "   $$y_k = \\underset{y\\in\\mathbb{R}^N}{\\arg\\min}\\ \\dfrac{\\gamma+\\varrho}{2}y^Ty - \\lambda_{t-1}^Ty - \\varrho(x_t+A_1\\overline{x}_t)^Ty$$\n",
    "\n",
    "   Попробуем решить самим, без решателя. Пусть мы обозначим $i$ координату вектора $v$ как $v[i]$\n",
    "\n",
    "    $$y_k[i] = \\underset{y\\in\\mathbb{R}}{\\arg\\min}\\ \\dfrac{\\gamma+\\varrho}{2}y[i]^2 - \\lambda_{t-1}[i]y[i] - \\varrho(x_t+[-E_N;0_{N\\times M}]\\overline{x}_t)[i]y[i]$$\n",
    "\n",
    "   Тоже самое\n",
    "\n",
    "   $$y_k[i] = \\underset{y\\in\\mathbb{R}}{\\arg\\min}\\ \\dfrac{\\gamma+\\varrho}{2}y[i]^2 - \\lambda_{t-1}[i]y[i] - \\varrho(x_t[i]-\\overline{x}_t[i])y[i]$$\n",
    "\n",
    "   Но заметим, что тут частная производная получается очевидная и градиент соотвественно\n",
    "\n",
    "   $$\\nabla y = (\\gamma + \\varrho)y - \\lambda_{t-1}-\\varrho(x_t - [E_N;0_{N \\times M}]\\overline{x}_t)$$.\n",
    "\n",
    "   Заметим также, что вторые частные производные равны все $(\\gamma + \\varrho)$ и они тогда положительный, а значит минимум будет не бесконечным.\n",
    "\n",
    "   Минимальное значение должно быть при градиенте равным нулю, а значит\n",
    "\n",
    "   $$ y_k = \\dfrac{\\lambda_{t-1} + \\varrho(x_t - [E_N;0_{N \\times M}]\\overline{x}_t)}{\\gamma + \\varrho}$$\n",
    "\n",
    "7. Обновляем $\\lambda_t$\n",
    "    $$\\lambda_t = \\lambda_{t-1} + \\varrho(A_0x_t + A_1\\overline{x}_t - y_t)$$\n",
    "8. Считаем специальную метрику, по которой будем выбирать лучшее решение, где $l$ - какая-то функция ошибки от $x_t$ и $\\overline{x}_t$\n",
    "\n",
    "    $$\\eta_t = -x_t^TPx_t + \\mu\\max(l(x_t, \\overline{x}_t), 0)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc139c06-55e4-44ed-8ac4-2b62f30e288d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solverMdMCQKP_2ADMM(profits: np.ndarray, \n",
    "                        groups: np.ndarray, \n",
    "                        weights: np.ndarray, \n",
    "                        capacity: np.ndarray, \n",
    "                        x_0: np.ndarray = None, #need to validate from here\n",
    "                        zu_0: np.ndarray = None,\n",
    "                        lambda_0: np.ndarray = None,\n",
    "                        epochs: np.uint64 = 20,\n",
    "                        rho: np.float64 = None, \n",
    "                        alpha: np.float64 = None,\n",
    "                        beta: np.float64 = None,\n",
    "                        mu: np.float64 = None,\n",
    "                        eps: np.float64 = None,\n",
    "                       ):\n",
    "    # validator raise ValueError if argument is not valid\n",
    "    N, M, K = validatorMdMCQ(profits, groups, weights, capacity)\n",
    "    # TODO validate constant and initial values\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b5ec1de-131b-4ad2-b5d2-918f4b7e529c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solverMdMCQKP_3ADMM(profits: np.ndarray, \n",
    "                        groups: np.ndarray, \n",
    "                        weights: np.ndarray, \n",
    "                        capacity: np.ndarray, \n",
    "                        x_0: np.ndarray = None, #need to validate from here\n",
    "                        zu_0: np.ndarray = None,\n",
    "                        y_0: np.ndarray = None,\n",
    "                        lambda_0: np.ndarray = None,\n",
    "                        epochs: np.uint64 = 20,\n",
    "                        rho: np.float64 = None, \n",
    "                        alpha: np.float64 = None,\n",
    "                        beta: np.float64 = None,\n",
    "                        gamma: np.float64 = None,\n",
    "                        mu: np.float64 = None,\n",
    "                        eps: np.float64 = None,\n",
    "                        loss = None\n",
    "                       ):\n",
    "    # validator raise ValueError if argument is not valid\n",
    "    N, M, K = validatorMdMCQ(profits, groups, weights, capacity)\n",
    "    A_1 = np.zeros((N, N + M))\n",
    "    for i in range(N):\n",
    "        A_1[i, i] = -1\n",
    "    # TODO validate constant and initial values\n",
    "    epochs += 1\n",
    "    x = np.full(epochs, x_0)\n",
    "    zu = np.full(epochs, zu_0)\n",
    "    y = np.full(epochs, y_0)\n",
    "    lamb = np.full(epochs, lambda_0)\n",
    "    metrics = np.zeros(epochs)\n",
    "    # TODO calculate metrics for zero\n",
    "    for curr_epoch in range(1, epochs):\n",
    "        prev_epoch = curr_epoch - 1\n",
    "        # Qubo block\n",
    "        Q = -profit + alpha / 2 * groups.T * groups + rho / 2 * np.eye(N)\n",
    "        # TODO\n",
    "        # Convex block\n",
    "        q = lamb[prev_epoch] + rho * (x[curr_epoch] - y[prev_epoch])\n",
    "        cones = clarabel.NonnegativeConeT(M)\n",
    "        solver = clarabel.DefaultSolver(rho * np.eye(N), q, weights, capacity, cones, clarabel_settings)\n",
    "        solution = solver.solve()\n",
    "        if not solution.status:\n",
    "            raise \"Solution not found for convex block\"\n",
    "        zu[curr_epoch] = np.hstack([solution.x, solution.z])\n",
    "        # Convex + quadratic block\n",
    "        y[curr_epoch] = (lamb[prev_epoch] + rho * (x[curr_epoch] + A_1 * zu[curr_epoch])) / (gamma + rho)\n",
    "        # update lambda\n",
    "        lamb[curr_epoch] = lamb[prev_epoch] + rho * (x[curr_epoch] + A_1 * zu[curr_epoch] - y[curr_epoch])\n",
    "        # calculate metrics\n",
    "        metrics[curr_epoch] = - x[curr_epoch].T * profit * x[curr_epoch] + mu * loss(x[curr_epoch], zu[curr_epoch])\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
